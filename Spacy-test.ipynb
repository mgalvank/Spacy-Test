{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Carry out a random act of kindness, with no expectation of reward."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = nlp(unicode(\"Carry out a random act of kindness, with no expectation of reward.\"))\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Carry',\n",
       " u'out',\n",
       " u'a',\n",
       " u'random',\n",
       " u'act',\n",
       " u'of',\n",
       " u'kindness',\n",
       " u',',\n",
       " u'with',\n",
       " u'no',\n",
       " u'expectation',\n",
       " u'of',\n",
       " u'reward',\n",
       " u'.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List out all the tokens\n",
    "tokenizer = [token.orth_ for token in sentence]\n",
    "tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Carry, u'VB'),\n",
       " (out, u'RP'),\n",
       " (a, u'DT'),\n",
       " (random, u'JJ'),\n",
       " (act, u'NN'),\n",
       " (of, u'IN'),\n",
       " (kindness, u'NN'),\n",
       " (,, u','),\n",
       " (with, u'IN'),\n",
       " (no, u'DT'),\n",
       " (expectation, u'NN'),\n",
       " (of, u'IN'),\n",
       " (reward, u'NN'),\n",
       " (., u'.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Parts of speech tagging\n",
    "pos = [(word,word.tag_) for word in sentence]\n",
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Asia, u'LOC'), (Soccer, u'ORG')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entity recognition\n",
    "sentence2 = nlp(unicode(\"Asia is the largest continent. Soccer is the best sport\"))\n",
    "entity = [(word,word.label_) for word in sentence2.ents]\n",
    "entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Asia', 'asia', 'PROPN', 'nsubj'),\n",
       " ('is', 'be', 'VERB', 'ROOT'),\n",
       " ('the', 'the', 'DET', 'det'),\n",
       " ('largest', 'large', 'ADJ', 'amod'),\n",
       " ('continent', 'continent', 'NOUN', 'attr'),\n",
       " ('.', '.', 'PUNCT', 'punct'),\n",
       " ('Soccer', 'soccer', 'NOUN', 'nsubj'),\n",
       " ('is', 'be', 'VERB', 'ROOT'),\n",
       " ('the', 'the', 'DET', 'det'),\n",
       " ('best', 'good', 'ADJ', 'amod'),\n",
       " ('sport', 'sport', 'NOUN', 'attr')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dependency tree\n",
    "dep_tree =[( str(word.text),  str(word.lemma_),  str(word.pos_),  str(word.dep_)) for word in sentence2]\n",
    "dep_tree\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
